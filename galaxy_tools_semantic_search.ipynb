{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae8a24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the data is loaded, the size is 7286\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer,losses, InputExample\n",
    "import json\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(\"galaxy_tools.json\",\"r\") as f:\n",
    "        data = json.load(f)\n",
    "    print(\"the data is loaded, the size is\", len(data))\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"File not found\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: Could not decode JSON from 'galaxy_tools.json'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d91bf725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "description\n",
      "panel_section_name\n",
      "labels\n",
      "edam_topics\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('galaxy_tools.csv')\n",
    "\n",
    "\n",
    "ID_COLUMN = 'id'\n",
    "NAME_COLUMN = 'name'\n",
    "DESCRIPTION_COLUMN = 'description'\n",
    "SECTION_COLUMN = 'panel_section_name'\n",
    "LABELS_COLUMN = 'labels'\n",
    "TOPICS_COLUMN = 'edam_topics'\n",
    "\n",
    "\n",
    "columns_to_process = [\n",
    "    NAME_COLUMN,\n",
    "    DESCRIPTION_COLUMN,\n",
    "    SECTION_COLUMN,\n",
    "    LABELS_COLUMN,\n",
    "    TOPICS_COLUMN\n",
    "]\n",
    "\n",
    "for data in df[columns_to_process]:\n",
    "    print(data if df[LABELS_COLUMN].notna else ''  )\n",
    "\n",
    "df[columns_to_process] = df[columns_to_process].fillna(' ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a74765ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def create_text_string(row):\n",
    "    \n",
    "    name = row[NAME_COLUMN]\n",
    "    description = row[DESCRIPTION_COLUMN]\n",
    "    section = row[SECTION_COLUMN]\n",
    "    labels_str = row[LABELS_COLUMN]\n",
    "    topics_str = row[TOPICS_COLUMN]\n",
    "\n",
    "    text_parts = []\n",
    "    \n",
    "\n",
    "    if name:\n",
    "        text_parts.append(f\"Tool: {name}.\")\n",
    "    if description:\n",
    "        text_parts.append(f\"Description: {description}.\")\n",
    "    if section:\n",
    "        text_parts.append(f\"Category: {section}.\")\n",
    "\n",
    "\n",
    "    if labels_str:\n",
    "        try:\n",
    "\n",
    "            labels_list = ast.literal_eval(labels_str)\n",
    "            if isinstance(labels_list, list) and labels_list:\n",
    "                text_parts.append(f\"Labels: {', '.join(labels_list)}.\")\n",
    "        except (ValueError, SyntaxError):\n",
    "            \n",
    "            text_parts.append(f\"Labels: {labels_str}.\")\n",
    "\n",
    "    if topics_str:\n",
    "        try:\n",
    "            topics_list = ast.literal_eval(topics_str)\n",
    "            if isinstance(topics_list, list) and topics_list:\n",
    "                text_parts.append(f\"Topics: {', '.join(topics_list)}.\")\n",
    "        except (ValueError, SyntaxError):\n",
    "            text_parts.append(f\"Topics: {topics_str}.\")\n",
    "\n",
    "    return \" \".join(text_parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669cbe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Tool: Upload File. Description: from your comp...\n",
      "1       Tool: UCSC Main. Description: table browser. C...\n",
      "2       Tool: UCSC Archaea. Description: table browser...\n",
      "3       Tool: SRA. Description: server. Category: Get ...\n",
      "4       Tool: EBI SRA. Description: ENA SRA. Category:...\n",
      "                              ...                        \n",
      "7281    Tool: Set External Metadata. Description:  . C...\n",
      "7282    Tool: Export History. Description:  . Category...\n",
      "7283    Tool: Export History to URI. Description:  . C...\n",
      "7284    Tool: Import History. Description:  . Category...\n",
      "7285       Tool: Data Fetch. Description:  . Category:  .\n",
      "Length: 7286, dtype: object\n"
     ]
    }
   ],
   "source": [
    "new_text_String = df.apply(create_text_string,1)\n",
    "\n",
    "\n",
    "print(new_text_String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc6e648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'id' : df[ID_COLUMN],\n",
    "    'text_string': new_text_String\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "cleaned_df = pd.DataFrame(data)\n",
    "cleaned_df.head\n",
    "\n",
    "\n",
    "cleaned_df.to_csv('cleaned_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d68aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhri/Desktop/gitfiles/icoglabs/first/galaxy_tools/lib/python3.13/site-packages/torch/cuda/__init__.py:829: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc141bae29b441ab0279ed575cf1f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhri/Desktop/gitfiles/icoglabs/first/galaxy_tools/lib/python3.13/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='456' max='456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [456/456 18:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "FINETUNED_MODEL_PATH = \"finetuned_galaxy_model\"\n",
    "\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "train_examples = []\n",
    "for index, row in cleaned_df.iterrows():\n",
    "\n",
    "    tool_name = row['text_string'].split('.')[0]\n",
    "    full_text = row['text_string']\n",
    "    train_examples.append(InputExample(texts=[tool_name, full_text]))\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "\n",
    "num_epochs = 1 \n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)\n",
    "\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=FINETUNED_MODEL_PATH,\n",
    "          show_progress_bar=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d50d0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = SentenceTransformer('finetuned_galaxy_model')\n",
    "\n",
    "\n",
    "final_embeddings = final_model.encode(cleaned_df['text_string'].to_list())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c32516f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 7286 documents in batches of 4096...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:09<00:00,  4.63s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection('new_semantic_collection')\n",
    "\n",
    "\n",
    "BATCH_SIZE = 4096 \n",
    "\n",
    "\n",
    "num_documents = len(cleaned_df)\n",
    "\n",
    "\n",
    "print(f\"Adding {num_documents} documents in batches of {BATCH_SIZE}...\")\n",
    "for i in tqdm(range(0, num_documents, BATCH_SIZE)):\n",
    "\n",
    "    end_index = i + BATCH_SIZE\n",
    "    batch_embeddings = final_embeddings[i:end_index].tolist()\n",
    "    batch_metadatas = [{\"id\": doc_id} for doc_id in cleaned_df['id'].iloc[i:end_index].tolist()]\n",
    "    batch_documents = cleaned_df['text_string'].iloc[i:end_index].tolist()\n",
    "    batch_ids = cleaned_df['id'].iloc[i:end_index].tolist()\n",
    "\n",
    "    collection.add(\n",
    "        embeddings=batch_embeddings,\n",
    "        metadatas=batch_metadatas,\n",
    "        documents=batch_documents,\n",
    "        ids=batch_ids\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4d62205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_formatted_answer(results):\n",
    "    ids_list = results['ids'][0]\n",
    "    docs_list = results['documents'][0]\n",
    "    distances_list = results['distances'][0]\n",
    "\n",
    "    for i in range(len(ids_list)):\n",
    "        distance = distances_list[i]\n",
    "        cosine_similarity = 1 - (distance**2 / 2)\n",
    "\n",
    "        if cosine_similarity >= 0.1:\n",
    "            print(f\"Result {i+1}:\")\n",
    "            print(f\"  - Tool ID: {ids_list[i]}\")\n",
    "            print(f\"  - Content: {docs_list[i]}\")\n",
    "            print(f\"  - Raw Distance: {distance:.4f}\")\n",
    "            print(f\"  - Cosine Similarity: {cosine_similarity:.4f}\")\n",
    "\n",
    "            print(\"-\" * 20)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ef2f761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      "  - Tool ID: toolshed.g2.bx.psu.edu/repos/iuc/pipelign/pipelign/0.2+galaxy0\n",
      "  - Content: Tool: Automated multiple sequence. Description: alignment with pipelign. Category: Multiple Alignments.\n",
      "  - Raw Distance: 1.1127\n",
      "  - Cosine Similarity: 0.3810\n",
      "--------------------\n",
      "Result 2:\n",
      "  - Tool ID: toolshed.g2.bx.psu.edu/repos/devteam/fasta_nucleotide_changer/cshl_fasta_nucleotides_changer/1.0.2+galaxy2\n",
      "  - Content: Tool: RNA/DNA. Description: converter. Category: FASTA/FASTQ.\n",
      "  - Raw Distance: 1.2386\n",
      "  - Cosine Similarity: 0.2330\n",
      "--------------------\n",
      "Result 3:\n",
      "  - Tool ID: toolshed.g2.bx.psu.edu/repos/devteam/fasta_nucleotide_changer/cshl_fasta_nucleotides_changer/1.0.1\n",
      "  - Content: Tool: RNA/DNA. Description: converter. Category: FASTA/FASTQ.\n",
      "  - Raw Distance: 1.2386\n",
      "  - Cosine Similarity: 0.2330\n",
      "--------------------\n",
      "Result 4:\n",
      "  - Tool ID: toolshed.g2.bx.psu.edu/repos/devteam/fasta_nucleotide_changer/cshl_fasta_nucleotides_changer/1.0.2\n",
      "  - Content: Tool: RNA/DNA. Description: converter. Category: FASTA/FASTQ.\n",
      "  - Raw Distance: 1.2386\n",
      "  - Cosine Similarity: 0.2330\n",
      "--------------------\n",
      "Result 5:\n",
      "  - Tool ID: toolshed.g2.bx.psu.edu/repos/devteam/fasta_nucleotide_changer/cshl_fasta_nucleotides_changer/1.0.0\n",
      "  - Content: Tool: RNA/DNA. Description: converter. Category: FASTA/FASTQ.\n",
      "  - Raw Distance: 1.2386\n",
      "  - Cosine Similarity: 0.2330\n",
      "--------------------\n",
      "Result 6:\n",
      "  - Tool ID: toolshed.g2.bx.psu.edu/repos/nick/sequence_content_trimmer/sequence_content_trimmer/0.2.3\n",
      "  - Content: Tool: Sequence Content Trimmer. Description: trim reads based on certain bases. Category: Du Novo.\n",
      "  - Raw Distance: 1.2922\n",
      "  - Cosine Similarity: 0.1651\n",
      "--------------------\n",
      "Result 7:\n",
      "  - Tool ID: toolshed.g2.bx.psu.edu/repos/nick/sequence_content_trimmer/sequence_content_trimmer/0.1\n",
      "  - Content: Tool: Sequence Content Trimmer. Description: trim reads based on certain bases. Category: Du Novo.\n",
      "  - Raw Distance: 1.2922\n",
      "  - Cosine Similarity: 0.1651\n",
      "--------------------\n",
      "Result 8:\n",
      "  - Tool ID: toolshed.g2.bx.psu.edu/repos/iuc/extract_genomic_dna/Extract genomic DNA 1/3.0.3\n",
      "  - Content: Tool: Extract Genomic DNA. Description: using coordinates from assembled/unassembled genomes. Category: Fetch Sequences/Alignments.\n",
      "  - Raw Distance: 1.2976\n",
      "  - Cosine Similarity: 0.1581\n",
      "--------------------\n",
      "Result 9:\n",
      "  - Tool ID: toolshed.g2.bx.psu.edu/repos/iuc/extract_genomic_dna/Extract genomic DNA 1/3.0.3+galaxy3\n",
      "  - Content: Tool: Extract Genomic DNA. Description: using coordinates from assembled/unassembled genomes. Category: Fetch Sequences/Alignments.\n",
      "  - Raw Distance: 1.2976\n",
      "  - Cosine Similarity: 0.1581\n",
      "--------------------\n",
      "Result 10:\n",
      "  - Tool ID: toolshed.g2.bx.psu.edu/repos/iuc/extract_genomic_dna/Extract genomic DNA 1/3.0.3+galaxy2\n",
      "  - Content: Tool: Extract Genomic DNA. Description: using coordinates from assembled/unassembled genomes. Category: Fetch Sequences/Alignments.\n",
      "  - Raw Distance: 1.2976\n",
      "  - Cosine Similarity: 0.1581\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"sequence this DNA\"\n",
    "query_embedding = final_model.encode([query]).tolist()\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding,\n",
    "    n_results=10\n",
    ")\n",
    "\n",
    "print_formatted_answer(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb48907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galaxy_tools (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
